{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchdata==0.3.0\n",
      "  Downloading torchdata-0.3.0-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 2.6 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting torchvision==0.12.0\n",
      "  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchtext==0.12.0 in /opt/conda/lib/python3.7/site-packages (0.12.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.11.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchdata==0.3.0) (2.23.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.7/site-packages (from torchdata==0.3.0) (1.25.7)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (7.0.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (3.7.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.12.0) (4.43.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchdata==0.3.0) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchdata==0.3.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchdata==0.3.0) (2019.11.28)\n",
      "Installing collected packages: torchdata, torchvision\n",
      "Successfully installed torchdata-0.3.0 torchvision-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchdata==0.3.0 torchvision==0.12.0 torchtext==0.12.0 torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import torch\n",
    "from nltk.corpus import brown\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Output, save, and load brown embeddings\n",
    "\n",
    "model = gensim.models.Word2Vec(brown.sents())\n",
    "model.save('brown.embedding')\n",
    "\n",
    "w2v = gensim.models.Word2Vec.load('brown.embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDF():\n",
    "    data = {\"question\": [], \"answer\": []}\n",
    "    index = 0\n",
    "    train_iter, dev_iter = datasets.SQuAD2()\n",
    "    for context, question, answers, indices in train_iter:\n",
    "        if answers[0]:\n",
    "            data[\"question\"].append(question)\n",
    "            data[\"answer\"].append(answers[0])\n",
    "        index += 1\n",
    "    df =  pd.DataFrame.from_dict(data)\n",
    "    return df\n",
    "#### note: this function is from a comment on the forum here - https://knowledge.udacity.com/questions/888774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def prepare_text(sentence):\n",
    "    '''\n",
    "\n",
    "    Our text needs to be cleaned with a tokenizer. This function will perform that task.\n",
    "    https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "    '''\n",
    "    #tokens = word_tokenize(sentence)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['question_tokens'] = data['question'].apply(prepare_text)\n",
    "data['answer_tokens'] = data['answer'].apply(prepare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_tokens</th>\n",
       "      <th>answer_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>[when, did, beyonce, start, becoming, popular]</td>\n",
       "      <td>[in, the, late, 1990s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>[what, areas, did, beyonce, compete, in, when,...</td>\n",
       "      <td>[singing, and, dancing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "      <td>[when, did, beyonce, leave, destiny, s, child,...</td>\n",
       "      <td>[2003]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>[in, what, city, and, state, did, beyonce, gro...</td>\n",
       "      <td>[houston, texas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>[in, which, decade, did, beyonce, become, famous]</td>\n",
       "      <td>[late, 1990s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86816</th>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>[in, what, us, state, did, kathmandu, first, e...</td>\n",
       "      <td>[oregon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86817</th>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>Rangoon</td>\n",
       "      <td>[what, was, yangon, previously, known, as]</td>\n",
       "      <td>[rangoon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86818</th>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>Minsk</td>\n",
       "      <td>[with, what, belorussian, city, does, kathmand...</td>\n",
       "      <td>[minsk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86819</th>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>1975</td>\n",
       "      <td>[in, what, year, did, kathmandu, create, its, ...</td>\n",
       "      <td>[1975]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86820</th>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>Kathmandu Metropolitan City</td>\n",
       "      <td>[what, is, kmc, an, initialism, of]</td>\n",
       "      <td>[kathmandu, metropolitan, city]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86821 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0               When did Beyonce start becoming popular?   \n",
       "1      What areas did Beyonce compete in when she was...   \n",
       "2      When did Beyonce leave Destiny's Child and bec...   \n",
       "3          In what city and state did Beyonce  grow up?    \n",
       "4             In which decade did Beyonce become famous?   \n",
       "...                                                  ...   \n",
       "86816  In what US state did Kathmandu first establish...   \n",
       "86817               What was Yangon previously known as?   \n",
       "86818  With what Belorussian city does Kathmandu have...   \n",
       "86819  In what year did Kathmandu create its initial ...   \n",
       "86820                      What is KMC an initialism of?   \n",
       "\n",
       "                            answer  \\\n",
       "0                in the late 1990s   \n",
       "1              singing and dancing   \n",
       "2                             2003   \n",
       "3                   Houston, Texas   \n",
       "4                       late 1990s   \n",
       "...                            ...   \n",
       "86816                       Oregon   \n",
       "86817                      Rangoon   \n",
       "86818                        Minsk   \n",
       "86819                         1975   \n",
       "86820  Kathmandu Metropolitan City   \n",
       "\n",
       "                                         question_tokens  \\\n",
       "0         [when, did, beyonce, start, becoming, popular]   \n",
       "1      [what, areas, did, beyonce, compete, in, when,...   \n",
       "2      [when, did, beyonce, leave, destiny, s, child,...   \n",
       "3      [in, what, city, and, state, did, beyonce, gro...   \n",
       "4      [in, which, decade, did, beyonce, become, famous]   \n",
       "...                                                  ...   \n",
       "86816  [in, what, us, state, did, kathmandu, first, e...   \n",
       "86817         [what, was, yangon, previously, known, as]   \n",
       "86818  [with, what, belorussian, city, does, kathmand...   \n",
       "86819  [in, what, year, did, kathmandu, create, its, ...   \n",
       "86820                [what, is, kmc, an, initialism, of]   \n",
       "\n",
       "                         answer_tokens  \n",
       "0               [in, the, late, 1990s]  \n",
       "1              [singing, and, dancing]  \n",
       "2                               [2003]  \n",
       "3                     [houston, texas]  \n",
       "4                        [late, 1990s]  \n",
       "...                                ...  \n",
       "86816                         [oregon]  \n",
       "86817                        [rangoon]  \n",
       "86818                          [minsk]  \n",
       "86819                           [1975]  \n",
       "86820  [kathmandu, metropolitan, city]  \n",
       "\n",
       "[86821 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split(SRC, TRG):\n",
    "    \n",
    "    '''\n",
    "    Input: SRC, our list of questions from the dataset\n",
    "            TRG, our list of responses from the dataset\n",
    "\n",
    "    Output: Training and test datasets for SRC & TRG\n",
    "\n",
    "    '''\n",
    "    \n",
    "    SRC_train_dataset, SRC_test_dataset, TRG_train_dataset, TRG_test_dataset = train_test_split(SRC, TRG, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return SRC_train_dataset, SRC_test_dataset, TRG_train_dataset, TRG_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_train_dataset, SRC_test_dataset, TRG_train_dataset, TRG_test_dataset = split(data['question_tokens'], data['answer_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34614                         [who, shot, queen, victoria]\n",
       "84775    [how, many, people, are, on, the, territorial,...\n",
       "75487            [where, does, sr, 94, merge, with, i, 15]\n",
       "24088    [when, did, natural, bronze, start, to, be, us...\n",
       "36068    [who, was, the, final, king, of, the, attalid,...\n",
       "                               ...                        \n",
       "6265                  [what, is, the, biggest, known, dog]\n",
       "54886             [what, encoding, does, charis, sil, use]\n",
       "76820            [who, made, the, demonstration, in, 1943]\n",
       "860      [at, what, age, did, frédéric, start, giving, ...\n",
       "15795       [where, is, corruption, even, more, prevalent]\n",
       "Name: question_tokens, Length: 69456, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34614                            [roderick, maclean]\n",
       "84775                                     [nineteen]\n",
       "75487                                  [at, miramar]\n",
       "24088                                     [5500, bc]\n",
       "36068                                 [attalus, iii]\n",
       "                            ...                     \n",
       "6265                              [english, mastiff]\n",
       "54886    [graphite, opentype, or, aat, technologies]\n",
       "76820                              [luria, delbrück]\n",
       "860                                              [7]\n",
       "15795                     [non, privatized, sectors]\n",
       "Name: answer_tokens, Length: 69456, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.num_words = 0\n",
    "        \n",
    "        self.add_token('<UNK>')\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token not in self.word2index:\n",
    "            self.word2index[token] = self.num_words\n",
    "            self.word2count[token] = 1\n",
    "            self.index2word[self.num_words] = token\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[token] += 1\n",
    "\n",
    "    def add_tokens(self, tokens):\n",
    "        for token in tokens:\n",
    "            self.add_token(token)\n",
    "            \n",
    "    def discard_rare_words(self, min_count):\n",
    "        tokens_to_remove = []\n",
    "        for token in self.word2count:\n",
    "            if self.word2count[token] < min_count:\n",
    "                tokens_to_remove.append(token)\n",
    "\n",
    "        for token in tokens_to_remove:\n",
    "            del self.word2index[token]\n",
    "            del self.word2count[token]\n",
    "\n",
    "        self.index2word = {index: token for token, index in self.word2index.items()}\n",
    "        self.num_words = len(self.word2index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_words\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Vocabulary size: {self.num_words}\"\n",
    "\n",
    "    def token_to_index(self, token):\n",
    "        return self.word2index.get(token, self.word2index['<UNK>'])\n",
    "\n",
    "    def index_to_token(self, index):\n",
    "        return self.index2word.get(index, '<UNK>')\n",
    "\n",
    "    def get_token_count(self, token):\n",
    "        return self.word2count.get(token, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Vocabulary()\n",
    "vocabulary_src = Vocabulary()\n",
    "vocabulary_trg = Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in SRC_train_dataset:\n",
    "    vocabulary.add_tokens(row)\n",
    "    vocabulary_src.add_tokens(row)\n",
    "for row in SRC_test_dataset:\n",
    "    vocabulary.add_tokens(row)\n",
    "    vocabulary_src.add_tokens(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in TRG_train_dataset:\n",
    "    vocabulary.add_tokens(row)\n",
    "    vocabulary_trg.add_tokens(row)\n",
    "for row in TRG_test_dataset:\n",
    "    vocabulary.add_tokens(row)\n",
    "    vocabulary_trg.add_tokens(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 52519\n",
      "5\n",
      "queen\n",
      "9500\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)\n",
    "print(vocabulary.token_to_index('how'))\n",
    "print(vocabulary.index_to_token(3))\n",
    "print(vocabulary.get_token_count('how'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 30359\n"
     ]
    }
   ],
   "source": [
    "vocabulary.discard_rare_words(2)\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 36743\n"
     ]
    }
   ],
   "source": [
    "vocabulary_src.discard_rare_words(1)\n",
    "print(vocabulary_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 37896\n"
     ]
    }
   ],
   "source": [
    "vocabulary_trg.discard_rare_words(1)\n",
    "print(vocabulary_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.word2index['<UNK>'] = len(vocabulary.word2index)\n",
    "vocabulary_src.word2index['<UNK>'] = len(vocabulary_src.word2index)\n",
    "vocabulary_trg.word2index['<UNK>'] = len(vocabulary_trg.word2index)\n",
    "def turn_to_indices_src(dataset):    \n",
    "    # Create an empty list to store the indices\n",
    "    dataset_indices = []\n",
    "\n",
    "    # Iterate through each row in the dataset\n",
    "    for row in dataset:\n",
    "        # Create an empty list to store the indices of tokens in the row\n",
    "        row_indices = []\n",
    "\n",
    "        # Iterate through each token in the row\n",
    "        for token in row:\n",
    "        # Convert the token to its index using the token_to_index function\n",
    "            if token in vocabulary_src.word2index:\n",
    "                index = vocabulary_src.word2index[token]\n",
    "            else:\n",
    "                index = vocabulary_src.word2index['<UNK>']\n",
    "\n",
    "            # Append the index to the row_indices list\n",
    "            row_indices.append(index)\n",
    "\n",
    "        # Append the row_indices list to the dataset_indices list\n",
    "        dataset_indices.append(row_indices)\n",
    "    return dataset_indices\n",
    "\n",
    "def turn_to_indices_trg(dataset):    \n",
    "    # Create an empty list to store the indices\n",
    "    dataset_indices = []\n",
    "\n",
    "    # Iterate through each row in the dataset\n",
    "    for row in dataset:\n",
    "        # Create an empty list to store the indices of tokens in the row\n",
    "        row_indices = []\n",
    "\n",
    "        # Iterate through each token in the row\n",
    "        for token in row:\n",
    "        # Convert the token to its index using the token_to_index function\n",
    "            if token in vocabulary_trg.word2index:\n",
    "                index = vocabulary_trg.word2index[token]\n",
    "            else:\n",
    "                index = vocabulary_trg.word2index['<UNK>']\n",
    "\n",
    "            # Append the index to the row_indices list\n",
    "            row_indices.append(index)\n",
    "\n",
    "        # Append the row_indices list to the dataset_indices list\n",
    "        dataset_indices.append(row_indices)\n",
    "    return dataset_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list_train = turn_to_indices_src(SRC_train_dataset)\n",
    "questions_list_test = turn_to_indices_src(SRC_test_dataset)\n",
    "answers_list_train = turn_to_indices_trg(TRG_train_dataset)\n",
    "answers_list_test = turn_to_indices_trg(TRG_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(list_of_lists):\n",
    "\n",
    "    # Calculate the lengths of the inner lists\n",
    "    lengths = [len(inner_list) for inner_list in list_of_lists]\n",
    "\n",
    "    # Sort the lengths\n",
    "    sorted_lengths = sorted(lengths)\n",
    "    \n",
    "    # Find the median length\n",
    "    if len(sorted_lengths) % 2 == 0:\n",
    "        median_length = (sorted_lengths[len(sorted_lengths) // 2] + sorted_lengths[len(sorted_lengths) // 2 - 1]) / 2\n",
    "    else:\n",
    "        median_length = sorted_lengths[len(sorted_lengths) // 2]\n",
    "        \n",
    "    return median_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_median(questions_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_median(answers_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_inner_lists(list_of_lists, max_length):\n",
    "    truncated_list_of_lists = [inner_list[:max_length] for inner_list in list_of_lists]\n",
    "    return truncated_list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_question = 10\n",
    "max_length_answer = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list_train = trim_inner_lists(questions_list_train, max_length_question)\n",
    "questions_list_test = trim_inner_lists(questions_list_test, max_length_question)\n",
    "answers_list_train = trim_inner_lists(answers_list_train, max_length_answer)\n",
    "answers_list_test = trim_inner_lists(answers_list_test, max_length_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_questions_list_train = [seq + [0] * (max_length_question - len(seq)) for seq in questions_list_train]\n",
    "padded_questions_list_test = [seq + [0] * (max_length_question - len(seq)) for seq in questions_list_test]\n",
    "padded_answers_list_train = [seq + [0] * (max_length_answer - len(seq)) for seq in answers_list_train]\n",
    "padded_answers_list_test = [seq + [0] * (max_length_answer - len(seq)) for seq in answers_list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(padded_questions_list_train, padded_answers_list_train))\n",
    "test_data = list(zip(padded_questions_list_test, padded_answers_list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69456"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_subset = train_data[0:9600]\n",
    "test_data_subset = test_data[0:9600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence, label = self.data[index]\n",
    "        return torch.tensor(sequence), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_data)\n",
    "test_dataset = MyDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_subset = MyDataset(train_data_subset)\n",
    "test_dataset_subset = MyDataset(test_data_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_subset = DataLoader(train_dataset_subset, batch_size=32, shuffle=True)\n",
    "test_dataloader_subset = DataLoader(test_dataset_subset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# pytorch boilerplate that determines whether a GPU is present or not,\n",
    "# this determines whether our dataset or model can to moved to a GPU\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretend that we're iterating over the iterator and print out the print element\n",
    "test_batch = next(iter(train_dataloader))\n",
    "src,trg = test_batch\n",
    "src = src.T\n",
    "trg = trg.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the code for the Encoder, Decoder and Seq2Seq model was from this source - http://ethen8181.github.io/machine-learning/deep_learning/seq2seq/1_torch_seq2seq_intro.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of this code was suggested by this mentor in this query - https://knowledge.udacity.com/questions/908515\n",
    "Small adjustments were made to it for my specific code and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjustable parameters\n",
    "INPUT_DIM = len(vocabulary_src)\n",
    "OUTPUT_DIM = len(vocabulary_trg)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Input :\n",
    "        - source batch\n",
    "    Layer : \n",
    "        source batch -> Embedding -> LSTM\n",
    "    Output :\n",
    "        - LSTM hidden state\n",
    "        - LSTM cell state\n",
    "\n",
    "    Parmeters\n",
    "    ---------\n",
    "    input_dim : int\n",
    "        Input dimension, should equal to the source vocab size.\n",
    "    \n",
    "    emb_dim : int\n",
    "        Embedding layer's dimension.\n",
    "        \n",
    "    hid_dim : int\n",
    "        LSTM Hidden/Cell state's dimension.\n",
    "        \n",
    "    n_layers : int\n",
    "        Number of LSTM layers.\n",
    "        \n",
    "    dropout : float\n",
    "        Dropout for the LSTM layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, emb_dim: int, hid_dim: int, n_layers: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "\n",
    "    def forward(self, src_batch: torch.LongTensor):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        src_batch : 2d torch.LongTensor\n",
    "            Batched tokenized source sentence of shape [sent len, batch size].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        hidden, cell : 3d torch.LongTensor\n",
    "            Hidden and cell state of the LSTM layer. Each state's shape\n",
    "            [n layers * n directions, batch size, hidden dim]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(src_batch) # [sent len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # outputs -> [sent len, batch size, hidden dim * n directions]\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 32, 512]), torch.Size([2, 32, 512]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
    "hidden, cell = encoder(src)\n",
    "hidden.shape, cell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Input :\n",
    "        - first token in the target batch\n",
    "        - LSTM hidden state from the encoder\n",
    "        - LSTM cell state from the encoder\n",
    "    Layer :\n",
    "        target batch -> Embedding -- \n",
    "                                   |\n",
    "        encoder hidden state ------|--> LSTM -> Linear\n",
    "                                   |\n",
    "        encoder cell state   -------\n",
    "        \n",
    "    Output :\n",
    "        - prediction\n",
    "        - LSTM hidden state\n",
    "        - LSTM cell state\n",
    "\n",
    "    Parmeters\n",
    "    ---------\n",
    "    output : int\n",
    "        Output dimension, should equal to the target vocab size.\n",
    "    \n",
    "    emb_dim : int\n",
    "        Embedding layer's dimension.\n",
    "        \n",
    "    hid_dim : int\n",
    "        LSTM Hidden/Cell state's dimension.\n",
    "        \n",
    "    n_layers : int\n",
    "        Number of LSTM layers.\n",
    "        \n",
    "    dropout : float\n",
    "        Dropout for the LSTM layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_dim: int, emb_dim: int, hid_dim: int, n_layers: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, trg: torch.LongTensor, hidden: torch.FloatTensor, cell: torch.FloatTensor):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trg : 1d torch.LongTensor\n",
    "            Batched tokenized source sentence of shape [batch size].\n",
    "            \n",
    "        hidden, cell : 3d torch.FloatTensor\n",
    "            Hidden and cell state of the LSTM layer. Each state's shape\n",
    "            [n layers * n directions, batch size, hidden dim]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prediction : 2d torch.LongTensor\n",
    "            For each token in the batch, the predicted target vobulary.\n",
    "            Shape [batch size, output dim]\n",
    "\n",
    "        hidden, cell : 3d torch.FloatTensor\n",
    "            Hidden and cell state of the LSTM layer. Each state's shape\n",
    "            [n layers * n directions, batch size, hidden dim]\n",
    "        \"\"\"\n",
    "        # [1, batch size, emb dim], the 1 serves as sent len\n",
    "        embedded = self.embedding(trg.unsqueeze(0))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.out(outputs.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32154)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 37896]), torch.Size([2, 32, 512]), torch.Size([2, 32, 512]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT).to(device)\n",
    "\n",
    "# notice that we are not passing the entire the .trg\n",
    "prediction, hidden, cell = decoder(trg[0], hidden, cell)\n",
    "prediction.shape, hidden.shape, cell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            'Hidden dimensions of encoder and decoder must be equal!'\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            'Encoder and decoder must have equal number of layers!'\n",
    "\n",
    "    def forward(self, src_batch: torch.LongTensor, trg_batch: torch.LongTensor,\n",
    "                teacher_forcing_ratio: float=0.5):\n",
    "\n",
    "        max_len, batch_size = trg_batch.shape\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # last hidden & cell state of the encoder is used as the decoder's initial hidden state\n",
    "        hidden, cell = self.encoder(src_batch)\n",
    "\n",
    "        trg = trg_batch[0]\n",
    "        for i in range(1, max_len):\n",
    "            prediction, hidden, cell = self.decoder(trg, hidden, cell)\n",
    "            outputs[i] = prediction\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                trg = trg_batch[i]\n",
    "            else:\n",
    "                trg = prediction.argmax(1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(36743, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(37896, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (out): Linear(in_features=512, out_features=37896, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that this implementation assumes that the size of the hidden layer,\n",
    "# and the number of layer are the same between the encoder and decoder\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "seq2seq = Seq2Seq(encoder, decoder, device).to(device)\n",
    "seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 37896])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = seq2seq(src, trg)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 45,904,648 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(seq2seq):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(seq2seq.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that only a subset was used to train as with the full set of data, the model was training for over 4 hours and was still not close to being finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 1/300, Loss: 10.529274940490723\n",
      "Epoch: 1, Batch: 11/300, Loss: 5.48054313659668\n",
      "Epoch: 1, Batch: 21/300, Loss: 6.142960548400879\n",
      "Epoch: 1, Batch: 31/300, Loss: 6.650991439819336\n",
      "Epoch: 1, Batch: 41/300, Loss: 6.264608383178711\n",
      "Epoch: 1, Batch: 51/300, Loss: 6.003070831298828\n",
      "Epoch: 1, Batch: 61/300, Loss: 6.554052829742432\n",
      "Epoch: 1, Batch: 71/300, Loss: 5.9720377922058105\n",
      "Epoch: 1, Batch: 81/300, Loss: 6.671511650085449\n",
      "Epoch: 1, Batch: 91/300, Loss: 6.475656032562256\n",
      "Epoch: 1, Batch: 101/300, Loss: 5.888495445251465\n",
      "Epoch: 1, Batch: 111/300, Loss: 4.94251823425293\n",
      "Epoch: 1, Batch: 121/300, Loss: 6.292538642883301\n",
      "Epoch: 1, Batch: 131/300, Loss: 5.973886489868164\n",
      "Epoch: 1, Batch: 141/300, Loss: 6.54754638671875\n",
      "Epoch: 1, Batch: 151/300, Loss: 6.553583145141602\n",
      "Epoch: 1, Batch: 161/300, Loss: 6.183943271636963\n",
      "Epoch: 1, Batch: 171/300, Loss: 5.77127742767334\n",
      "Epoch: 1, Batch: 181/300, Loss: 6.275703430175781\n",
      "Epoch: 1, Batch: 191/300, Loss: 5.576815605163574\n",
      "Epoch: 1, Batch: 201/300, Loss: 6.5672078132629395\n",
      "Epoch: 1, Batch: 211/300, Loss: 5.7643609046936035\n",
      "Epoch: 1, Batch: 221/300, Loss: 6.776147842407227\n",
      "Epoch: 1, Batch: 231/300, Loss: 6.343571662902832\n",
      "Epoch: 1, Batch: 241/300, Loss: 6.362812519073486\n",
      "Epoch: 1, Batch: 251/300, Loss: 5.819782257080078\n",
      "Epoch: 1, Batch: 261/300, Loss: 6.460704326629639\n",
      "Epoch: 1, Batch: 271/300, Loss: 6.640124797821045\n",
      "Epoch: 1, Batch: 281/300, Loss: 5.870091915130615\n",
      "Epoch: 1, Batch: 291/300, Loss: 6.142664909362793\n",
      "Epoch: 2, Batch: 1/300, Loss: 5.030917167663574\n",
      "Epoch: 2, Batch: 11/300, Loss: 5.967374324798584\n",
      "Epoch: 2, Batch: 21/300, Loss: 5.774061679840088\n",
      "Epoch: 2, Batch: 31/300, Loss: 5.162739276885986\n",
      "Epoch: 2, Batch: 41/300, Loss: 5.522162914276123\n",
      "Epoch: 2, Batch: 51/300, Loss: 5.605436325073242\n",
      "Epoch: 2, Batch: 61/300, Loss: 5.9591875076293945\n",
      "Epoch: 2, Batch: 71/300, Loss: 5.758162975311279\n",
      "Epoch: 2, Batch: 81/300, Loss: 6.060526371002197\n",
      "Epoch: 2, Batch: 91/300, Loss: 6.143240928649902\n",
      "Epoch: 2, Batch: 101/300, Loss: 6.028457164764404\n",
      "Epoch: 2, Batch: 111/300, Loss: 4.7003068923950195\n",
      "Epoch: 2, Batch: 121/300, Loss: 5.592963218688965\n",
      "Epoch: 2, Batch: 131/300, Loss: 5.4436798095703125\n",
      "Epoch: 2, Batch: 141/300, Loss: 4.840942859649658\n",
      "Epoch: 2, Batch: 151/300, Loss: 5.678016662597656\n",
      "Epoch: 2, Batch: 161/300, Loss: 5.936118125915527\n",
      "Epoch: 2, Batch: 171/300, Loss: 5.726540565490723\n",
      "Epoch: 2, Batch: 181/300, Loss: 5.801177978515625\n",
      "Epoch: 2, Batch: 191/300, Loss: 5.543107509613037\n",
      "Epoch: 2, Batch: 201/300, Loss: 5.408207893371582\n",
      "Epoch: 2, Batch: 211/300, Loss: 5.585414409637451\n",
      "Epoch: 2, Batch: 221/300, Loss: 5.581083297729492\n",
      "Epoch: 2, Batch: 231/300, Loss: 6.3386030197143555\n",
      "Epoch: 2, Batch: 241/300, Loss: 5.839604377746582\n",
      "Epoch: 2, Batch: 251/300, Loss: 6.1948065757751465\n",
      "Epoch: 2, Batch: 261/300, Loss: 5.802911758422852\n",
      "Epoch: 2, Batch: 271/300, Loss: 5.683938980102539\n",
      "Epoch: 2, Batch: 281/300, Loss: 5.943202495574951\n",
      "Epoch: 2, Batch: 291/300, Loss: 5.778065204620361\n",
      "Epoch: 3, Batch: 1/300, Loss: 5.8177995681762695\n",
      "Epoch: 3, Batch: 11/300, Loss: 5.396586894989014\n",
      "Epoch: 3, Batch: 21/300, Loss: 5.888276100158691\n",
      "Epoch: 3, Batch: 31/300, Loss: 6.113975524902344\n",
      "Epoch: 3, Batch: 41/300, Loss: 6.190423011779785\n",
      "Epoch: 3, Batch: 51/300, Loss: 5.443976402282715\n",
      "Epoch: 3, Batch: 61/300, Loss: 4.850929260253906\n",
      "Epoch: 3, Batch: 71/300, Loss: 5.539475440979004\n",
      "Epoch: 3, Batch: 81/300, Loss: 5.834135055541992\n",
      "Epoch: 3, Batch: 91/300, Loss: 5.22830867767334\n",
      "Epoch: 3, Batch: 101/300, Loss: 5.900238990783691\n",
      "Epoch: 3, Batch: 111/300, Loss: 5.3657684326171875\n",
      "Epoch: 3, Batch: 121/300, Loss: 5.248898029327393\n",
      "Epoch: 3, Batch: 131/300, Loss: 6.21514368057251\n",
      "Epoch: 3, Batch: 141/300, Loss: 6.238295555114746\n",
      "Epoch: 3, Batch: 151/300, Loss: 5.567636966705322\n",
      "Epoch: 3, Batch: 161/300, Loss: 5.599146366119385\n",
      "Epoch: 3, Batch: 171/300, Loss: 5.617737293243408\n",
      "Epoch: 3, Batch: 181/300, Loss: 6.186387538909912\n",
      "Epoch: 3, Batch: 191/300, Loss: 6.093712329864502\n",
      "Epoch: 3, Batch: 201/300, Loss: 5.7783002853393555\n",
      "Epoch: 3, Batch: 211/300, Loss: 5.656024932861328\n",
      "Epoch: 3, Batch: 221/300, Loss: 4.884775161743164\n",
      "Epoch: 3, Batch: 231/300, Loss: 5.492725372314453\n",
      "Epoch: 3, Batch: 241/300, Loss: 5.514199733734131\n",
      "Epoch: 3, Batch: 251/300, Loss: 4.94802188873291\n",
      "Epoch: 3, Batch: 261/300, Loss: 5.122299671173096\n",
      "Epoch: 3, Batch: 271/300, Loss: 5.530669212341309\n",
      "Epoch: 3, Batch: 281/300, Loss: 5.295457363128662\n",
      "Epoch: 3, Batch: 291/300, Loss: 5.60837459564209\n"
     ]
    }
   ],
   "source": [
    "seq2seq.train()\n",
    "num_epochs = 3\n",
    "log_interval = 10  # Define the log interval\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (src, trg)  in enumerate(train_dataloader_subset):\n",
    "        src = src.to(device)\n",
    "        src = src.T\n",
    "        trg = trg.to(device)\n",
    "        trg = trg.T\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = seq2seq(src, trg)\n",
    "        \n",
    "        outputs = outputs.view(-1, outputs.size(2))  # Reshape outputs tensor\n",
    "        trg = trg.reshape(-1)  # Reshape trg tensor\n",
    "        \n",
    "        loss = criterion(outputs, trg)\n",
    "        \n",
    "        if loss < best_valid_loss:\n",
    "            best_valid_loss = loss\n",
    "            torch.save(seq2seq.state_dict(), 'tut1-model.pt')\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch+1}, Batch: {batch_idx+1}/{len(train_dataloader_subset)}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.load_state_dict(torch.load('tut1-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1/300\n",
      "Batch: 11/300\n",
      "Batch: 21/300\n",
      "Batch: 31/300\n",
      "Batch: 41/300\n",
      "Batch: 51/300\n",
      "Batch: 61/300\n",
      "Batch: 71/300\n",
      "Batch: 81/300\n",
      "Batch: 91/300\n",
      "Batch: 101/300\n",
      "Batch: 111/300\n",
      "Batch: 121/300\n",
      "Batch: 131/300\n",
      "Batch: 141/300\n",
      "Batch: 151/300\n",
      "Batch: 161/300\n",
      "Batch: 171/300\n",
      "Batch: 181/300\n",
      "Batch: 191/300\n",
      "Batch: 201/300\n",
      "Batch: 211/300\n",
      "Batch: 221/300\n",
      "Batch: 231/300\n",
      "Batch: 241/300\n",
      "Batch: 251/300\n",
      "Batch: 261/300\n",
      "Batch: 271/300\n",
      "Batch: 281/300\n",
      "Batch: 291/300\n"
     ]
    }
   ],
   "source": [
    "seq2seq.eval()\n",
    "\n",
    "epoch_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (src, trg)  in enumerate(test_dataloader_subset):\n",
    "        src = src.to(device)\n",
    "        src = src.T\n",
    "        trg = trg.to(device)\n",
    "        trg = trg.T\n",
    "        \n",
    "        # turn off teacher forcing\n",
    "        outputs = seq2seq(src, trg)\n",
    "\n",
    "        # trg = [trg sent len, batch size]\n",
    "        # output = [trg sent len, batch size, output dim]\n",
    "        outputs = outputs.view(-1, outputs.size(2))  # Reshape outputs tensor\n",
    "        trg = trg.reshape(-1)  # Reshape trg tensor\n",
    "        \n",
    "        loss = criterion(outputs, trg)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f'Batch: {batch_idx+1}/{len(test_dataloader_subset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 6.262801626523336\n"
     ]
    }
   ],
   "source": [
    "print(f'| Test Loss: {epoch_loss / len(test_dataloader_subset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a bonus, here are my chatbot interaction functions. My chatbot was only trained on a subset of the data, so most responses are that it does not know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_to_indices(question):\n",
    "    indexed_question = []\n",
    "    for elem in question:\n",
    "        indexed_question.append(vocabulary_src.token_to_index(elem))\n",
    "    return indexed_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_to_indices_answer(answer):\n",
    "    indexed_answer = []\n",
    "    for elem in answer:\n",
    "        indexed_answer.append(vocabulary_trg.token_to_index(elem))\n",
    "    return indexed_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_question(question):\n",
    "    if len(question)>10:\n",
    "        return question[0:10]\n",
    "    elif len(question)==10:\n",
    "        return question\n",
    "    else:\n",
    "        padding = 10 - len(question)\n",
    "        return question + [0] * padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_answer(question):\n",
    "    if len(question)>4:\n",
    "        return question[0:4]\n",
    "    elif len(question)==4:\n",
    "        return question\n",
    "    else:\n",
    "        padding = 4 - len(question)\n",
    "        return question + [0] * padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_question(question):\n",
    "    question = torch.tensor(question)\n",
    "    return question.unsqueeze(0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_question(question):\n",
    "    return tensor_question(size_question(turn_to_indices(question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_answer(answer):\n",
    "    return tensor_question(size_answer(turn_to_indices_answer(answer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_a_question(question, predicted_answer):\n",
    "    question = prepare_text(question)\n",
    "    answer = prepare_text(predicted_answer)\n",
    "    \n",
    "    question = prepare_question(question)\n",
    "    answer = prepare_answer(answer)\n",
    "    \n",
    "    seq2seq.eval()\n",
    "    outputs = seq2seq(question, answer)\n",
    "    \n",
    "    batch_size, num_examples, vocab_size = outputs.shape\n",
    "    reshaped_output = outputs.reshape(batch_size * num_examples, vocab_size)\n",
    "    #print(reshaped_output)\n",
    "    predicted_indices = np.argmax(reshaped_output.detach().numpy(), axis=1)\n",
    "    #print(predicted_indices)\n",
    "    predicted_tokens = [vocabulary_trg.index_to_token(index) for index in predicted_indices]\n",
    "    reshaped_predicted_tokens = np.array(predicted_tokens).reshape(num_examples, batch_size)\n",
    "    \n",
    "    response = list(reshaped_predicted_tokens[0]).remove('<UNK>')\n",
    "    # Remove the <UNK> token from the list\n",
    "\n",
    "    if response:\n",
    "        r = ' '.join(response)\n",
    "    else:\n",
    "        r = 'I do not know, sorry.'\n",
    "        \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not know, sorry.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_a_question('what country are you from?', 'england')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
